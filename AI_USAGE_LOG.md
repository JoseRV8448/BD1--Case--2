# Bitácora de Uso de IA - Caso #2: PromptSales

| Fecha | Estudiante | Prompt | Resultado | Validación & Proceso |
|-------|------------|--------|-----------|---------------------|
| 2024-10-31 | Lee Sang-cheol | "Diseñar 6 colecciones MongoDB para PromptContent con: providers externos (OpenAI, Gemini, etc.), MCP servers config, API logs completos, y tracking de solicitudes. Incorporar feedback del profesor: campo 'tipo' debe ir dentro de metadata embebido, logs deben tener request/response body completo" | AI generó diseño con 6 colecciones: contenido_generado, log_llamadas_api, configuracion_mcp, bitacora_solicitudes, integraciones_api, campana_mensajes | **Problemas iniciales:** 1) AI puso "tipo" como campo separado (contradice feedback profesor) 2) logs_api solo tenía status code sin body 3) configuracion_mcp sin deployment info de K8s **Correcciones aplicadas:** Moví "tipo" dentro de metadata como objeto embebido `metadata: { formato: "imagen", mime_type: "..." }`, expandí log_llamadas_api con campos `request: { body: {...} }` y `response: { body: {...} }` completos, agregué sección deployment en configuracion_mcp con `namespace_k8s, pod_name, host, port` **Validación:** Probé inserción con `mongosh` verificando dotación funciona `metadata.formato`, consulté logs con `db.log_llamadas_api.findOne()` confirmando body completo visible, verifiqué estructura K8s contra YAML deployment **Por qué funciona:** MongoDB permite objetos embebidos sin límite de profundidad, almacenar body completo facilita debugging, deployment info necesaria para MCP client connection **Optimización:** Eliminé campo redundante "status" en MCP servers (ya manejado con enabled:boolean) |
| 2024-11-01 | Lee Sang-cheol | "Generar script Node.js que llene MongoDB con 100 imágenes distribuidas en 12 categorías temáticas (electrónica, deportes, moda, etc). Cada documento debe tener: URL imagen, descripción amplia 100-150 palabras, 5-8 hashtags relevantes, vector embedding 1536 dimensiones usando OpenAI API" | AI entregó script con faker.js para datos random, 12 categorías hardcoded, descripciones 30 palabras, URLs fake unsplash, vectores arrays estáticos [0.1, 0.2...] | **Problemas encontrados:** 1) URLs unsplash fake no resuelven (links muertos) 2) Descripciones 20-30 palabras muy cortas para semantic search 3) Vector embeddings hardcoded no sirven para búsqueda real 4) Faker.js genera texto sin sentido **Correcciones:** Implementé integración Pexels API real con `axios` para URLs válidas permanentes CDN, expandí generación descripciones usando template literals con contexto específico por categoría logrando 120-150 palabras promedio, integré OpenAI embeddings API `text-embedding-3-small` (512 dims más económico que ada-002), agregué retry logic con exponential backoff para rate limits **Validación:** Descargué sample 10 imágenes verificando URLs funcionan y persisten, medí longitud descripciones con `desc.split(' ').length` promedio 143 palabras, probé similarity search calculando cosine similarity entre vectores retornando resultados semánticamente relevantes, calculé costo: 100 docs × 150 words × $0.00002/token ≈ $0.30 **Por qué funciona:** Pexels API gratuita da URLs permanentes sin expiración, descripciones largas con vocabulario rico mejoran vector embedding quality, OpenAI embeddings usa transformer para capturar semántica contextual **Trade-offs analizados:** text-embedding-3-small (512 dims, $0.00002/token) vs ada-002 (1536 dims, $0.0001/token) - elegí small por costo 5× menor con pérdida <5% accuracy según OpenAI docs |
| 2024-11-03 | Lee Sang-cheol | "Crear servidor MCP Node.js con 2 tools: (1) getContent: recibe descripción texto, retorna imágenes matching con hashtags usando Pinecone vector search; (2) generateCampaignMessages: recibe descripción campaña + público meta, genera 3 mensajes personalizados por segmento demográfico usando OpenAI GPT-4" | AI generó boilerplate MCP server con tools básicos, búsqueda simple MongoDB sin vectores, mensajes genéricos sin personalización demográfica | **Problemas:** 1) Tool getContent hacía búsqueda texto plano con `$regex` (lento, impreciso) 2) Pinecone integration ausente 3) generateCampaignMessages no tenía lógica segmentación demográfica 4) Input validation inexistente 5) Error handling con throw genérico **Correcciones implementadas:** Reemplacé búsqueda regex con Pinecone vector search workflow: query text → OpenAI embedding → Pinecone.query(vector, topK=10) → retrieve MongoDB docs by IDs, implementé input validation con Zod schema checking required fields + tipos, agregé segmentación demográfica con prompts específicos por edad/género/ubicación `"Genera mensaje para ${segmento.edad} en ${segmento.ubicacion} con tono ${segmento.tono}"`, implementé error handling granular con try-catch por tool + logging a MongoDB **Validación:** Probé getContent con query "zapatos deportivos rojos" retornando 8/10 resultados relevantes (2 false positives aceptables), medí latency: vector search 180ms + MongoDB fetch 45ms = 225ms total (cumple <300ms requirement), probé generateCampaignMessages con 3 segmentos generando mensajes distintivamente diferentes verificando tono/vocabulario apropiado por demografía, simulé 429 rate limit error verificando retry logic ejecuta correctamente con exponential backoff **Por qué funciona:** Pinecone vector DB optimizado para similarity search O(log n) vs regex O(n), embeddings capturan semántica mejor que keyword matching, GPT-4 few-shot prompting con ejemplos por segmento mejora relevancia, Zod validation previene crashes por input malformed **Limitaciones identificadas:** Pinecone free tier 1M vectors (suficiente para proyecto), OpenAI rate limits requieren queue management en producción, MCP protocol síncrono no ideal para long-running AI tasks (debería ser async con callbacks) |
| 2024-11-04 | Lee Sang-cheol | "Crear script de indexación que lea 100 documentos MongoDB contenido_generado, genere embeddings OpenAI si faltan, suba vectores a Pinecone con metadata (hashtags, tipo) para permitir filtered vector search" | AI dio script básico con loop síncrono individual insert, sin batch processing, sin manejo quota errors, sin progress tracking | **Problemas críticos:** 1) Loop síncrono 100× OpenAI API calls secuenciales duraría ~5min + alto rate limit risk 2) Sin verificación documentos ya indexados (re-indexing waste) 3) Pinecone upsert() individual costoso (network overhead) 4) Sin metadata filtering setup 5) Crash si 1 embedding falla **Correcciones:** Implementé batch processing 10 docs por request OpenAI usando `input: [text1, text2...]` reduciendo 100 calls a 10, agregué check `vector_embedding: { $exists: true }` skip docs ya embeddeados evitando trabajo duplicado, usé Pinecone batch upsert 100 vectors por llamada (límite API) optimizando network round-trips 10:1, configuré metadata fields en Pinecone index para filtered search `metadata: { tipo, hashtags, categoria }`, implementé error recovery: try-catch por batch + retry failed batches + logging failures a MongoDB **Validación:** Probé script con 100 docs: completó 12 segundos (vs ~300s secuencial), verificó skip correctamente 15 docs pre-existentes, confirmó 100 vectores en Pinecone dashboard con metadata visible, probé filtered query `filter: { tipo: { $eq: "imagen" } }` retornando solo imágenes, simulé network error mid-batch verificando recovery inserta successful vectors + re-intenta failed batch **Métricas:** Batch processing 25× speedup, OpenAI cost $0.30 total (100 docs × 150 words), Pinecone free tier usage 0.01% (100/1M vectors) **Por qué mejor:** Batching reduce latency (1 network call vs 100), amortiza API overhead, Pinecone metadata filtering evita post-processing en app layer (faster queries), error recovery asegura data consistency (no partial failures) |
| 2024-11-05 | Lee Sang-cheol | "Encontré error 429 OpenAI quota exceeded. Analizar alternativas: usar embeddings pre-computados gratis, cambiar a modelo más barato, implementar caching, o mock data para demo. Recomendar mejor approach para entregable académico con $0 budget" | AI sugirió: 1) Downgrade ada-002 a text-embedding-3-small (ya estaba usando), 2) Usar HuggingFace models gratis, 3) Mock embeddings random, 4) Pre-compute offline | **Análisis de opciones:** **Opción 1 HuggingFace (sentence-transformers):** PRO: Gratis, local execution, no rate limits; CON: embeddings diferentes dimensionalidad incompatible Pinecone index existente, requiere re-indexar todo **Opción 2 Mock random vectors:** PRO: Instant, $0; CON: Búsqueda semántica no funciona (random vectors no clustering), entregable no demuestra concepto real **Opción 3 Pre-compute offline con free credits:** PRO: Real embeddings, compatible; CON: OpenAI new account solo $5 credit agota rápido **Decisión tomada:** Combinación 2+3: usé mock vectors `Array(512).fill(0).map(() => Math.random())` para 85 docs maintaining estructura correcta, generé embeddings reales OpenAI para 15 docs sample críticos para demo usando free trial, documenté en README que production requiere funding con estimate cost $30/10K images **Validación & justificación:** Probé que mock vectors permiten flow completo funcionar (insert, query, retrieve) aunque resultados no semánticamente relevantes, 15 docs reales suficientes para demostrar accuracy en live demo específico, calculé ROI: $0 gasto vs $30 producción = viable para academic proof-of-concept, documenté limitación explícitamente en entregable con cost analysis y architecture diagrams mostrando dónde entra OpenAI **Por qué válido para entregable:** Profesor enfatizó "pruebas de concepto" no producción, arquitectura completa implementada y documentada demuestra comprensión técnica, trade-off cost vs functionality claramente explicado muestra engineering judgment, 429 error screenshot incluido como evidence de intento real API integration **Learning:** Academic projects requieren balance between ideal solution y pragmatic constraints, mock data aceptable SI arquitectura real está presente y limitations documentadas, API cost planning crítico para AI-based systems |
| 2024-11-06 | Lee Sang-cheol | "Configurar MongoDB en Docker container con persistent volume, script automático data seeding, y docker-compose.yml para levantar stack completo (MongoDB + Redis + MCP server) con un comando para team collaboration" | AI generó docker-compose básico MongoDB sin volumes, sin network config, sin health checks, sin environment variables management | **Problemas:** 1) Sin volume: data se pierde al reiniciar container 2) Sin network: containers no se pueden comunicar 3) Hardcoded passwords en compose file (security issue) 4) Sin depends_on: race conditions en startup 5) Sin health checks: MCP server arranca antes que MongoDB ready **Correcciones:** Configuré named volume `mongodb_data:/data/db` para persistence, creé custom network `promptsales_network: driver: bridge` conectando todos containers, moví secrets a `.env` file con `env_file: .env` en compose, agregué `depends_on: mongodb: condition: service_healthy` asegurando startup order, implementé health check MongoDB `test: mongosh --eval "db.adminCommand('ping')" interval: 10s` **Configuración adicional:** Script init seed `/docker-entrypoint-initdb.d/init.js` corre automáticamente al crear container first time insertando 100 docs, expose ports estratégicamente: MongoDB 27017 NO exposed externally (security), MCP 3001 exposed para client access, configuré resource limits `mem_limit: 512m` prevenir container consume toda RAM **Validación:** Probé `docker-compose up -d` levanta stack completo <30seg, verificó data persiste haciendo `docker-compose down && docker-compose up` data sigue ahí, probé connectivity entre containers `docker exec mcp_server ping mongodb` resuelve correctamente, confirmó init script corrió viendo `docker logs mongodb | grep "init.js"`, probé desde host machine connection MCP server `curl localhost:3001/health` responds OK **Por qué importante para team:** Docker elimina "works on my machine" problems, compose file es single source of truth infrastructure, volumes permiten easy backup `docker run --rm -v mongodb_data:/data -v $(pwd):/backup busybox tar czf /backup/mongodb-backup.tar.gz /data`, networking simplifica inter-service communication sin hardcoded IPs **Best practices aplicadas:** `.env` file in `.gitignore` protege secrets, health checks previenen cascading failures, resource limits evitan resource exhaustion, init scripts automate setup reducing onboarding friction |
